{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpLSW3xHP1-C",
        "outputId": "c970eaac-c668-4561-c0fc-7a033b6b8b50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Aok6zKu7Pmt4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pathlib as pl\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import shutil\n",
        "import pickle\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow.keras as tfk\n",
        "import keras\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix, auc, roc_curve\n",
        "\n",
        "def timestamp():\n",
        "  return datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os diretórios abaixo são mutáveis para testar outros datasets, lembre-se que o diretório do dataset deve ser uma pasta com as imagens .png, a separação em subpastas para as classes é realizada no próprio código"
      ],
      "metadata": {
        "id": "0JfcCSIbm3Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/walter-tiago/ai-images-dataset.git\n",
        "\n",
        "dataset_dir = pl.Path(\"/content/ai-images-dataset/dataset\")\n",
        "temp_dir = pl.Path(\"/content/ai-images-dataset/temporary\")\n",
        "model_dir = temp_dir / \"models\"\n",
        "train_dir = temp_dir / \"train\"\n",
        "log_dir = temp_dir / \"logs\"\n",
        "csv_dir = temp_dir / \"csv-files\"\n",
        "\n",
        "dataset_dir.mkdir(parents = True, exist_ok = True)\n",
        "model_dir.mkdir(parents = True, exist_ok = True)\n",
        "train_dir.mkdir(parents = True, exist_ok = True)\n",
        "log_dir.mkdir(parents = True, exist_ok = True)\n",
        "csv_dir.mkdir(parents = True, exist_ok = True)"
      ],
      "metadata": {
        "id": "9f3J8m0yQbLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os valores de input abaixo são mutáveis, contudo sua modificação pode ocasionar underfitting ou overfitting. **OBS.:** para um treino rápido, o melhor seria diminuir as épocas (epochs)"
      ],
      "metadata": {
        "id": "adgyiPwUmgQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input values:\n",
        "image_size = (50, 50)\n",
        "classes = [\"soil\", \"tree\"]\n",
        "batch_size = 128\n",
        "epochs = 256\n",
        "learning_rate = 0.001\n",
        "regularization_rate = 0.01\n",
        "num_ref_layer = 3 # number of (2D Conv layers) and (Dense layers)\n",
        "dropout_rate = 0.5\n",
        "validation_split = 0.3\n",
        "\n",
        "class_mode = \"categorical\"\n",
        "num_classes = len(classes)\n",
        "channels = 3  # RGB\n",
        "image_shape = image_size + (channels,)\n",
        "\n",
        "# Class folders:\n",
        "for class_name in classes:\n",
        "  class_dir = train_dir / class_name\n",
        "  class_dir.mkdir(parents=True, exist_ok=True)\n",
        "  for local_file in dataset_dir.iterdir():\n",
        "    local_file_name = local_file.name\n",
        "    if local_file.is_file() and class_name in local_file_name:\n",
        "      shutil.copy(local_file, class_dir / local_file.name)\n",
        "  print(f'{class_name.title()}: {len(list(class_dir.iterdir()))} samples.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYVl1krqQdUt",
        "outputId": "2643fdb7-8f96-4e4f-cae2-2eeac89b7831"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soil: 4448 samples.\n",
            "Tree: 2224 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Data generator:\n",
        "\n",
        "datagen = tfk.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function = tfk.applications.vgg19.preprocess_input,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    zoom_range = 0.1,\n",
        "    validation_split = validation_split\n",
        "    )\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = class_mode,\n",
        "    subset='training'\n",
        "    )\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = class_mode,\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        "    )\n",
        "\n",
        "class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
        "                'balanced', \n",
        "                classes = np.unique(train_generator.classes), \n",
        "                y = train_generator.classes\n",
        "                )\n",
        "\n",
        "print(f\"\\nClass weights: {classes} = {class_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CymSqzOUQe4W",
        "outputId": "0ebd44a4-d1f0-461c-fb23-a9ce7f3277bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4671 images belonging to 2 classes.\n",
            "Found 2001 images belonging to 2 classes.\n",
            "\n",
            "Class weights: ['soil', 'tree'] = [0.75 1.5 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este modelo sequencial de rede neural pode ser modificado para testes, novamente fique atento ao under ou overfitting"
      ],
      "metadata": {
        "id": "uYK1hmtCnYsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base model:\n",
        "\n",
        "base_model = tfk.applications.vgg19.VGG19(\n",
        "    weights = \"imagenet\", \n",
        "    include_top = False, \n",
        "    input_shape = image_shape\n",
        "    )\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tfk.models.Sequential()\n",
        "\n",
        "model.add(base_model)\n",
        "\n",
        "counter_layer = 0\n",
        "while counter_layer < num_ref_layer:\n",
        "  \n",
        "  model.add(\n",
        "      tfk.layers.Conv2D(\n",
        "          filters = batch_size / 2**(num_ref_layer - counter_layer),\n",
        "          kernel_size = (3, 3), \n",
        "          activation='relu', \n",
        "          padding='same',\n",
        "          input_shape = image_shape,))\n",
        "   \n",
        "  model.add(\n",
        "      tfk.layers.Conv2D(\n",
        "          filters = batch_size / 2**(num_ref_layer - counter_layer),\n",
        "          kernel_size = (3, 3), \n",
        "          activation='relu', \n",
        "          padding='same',\n",
        "          input_shape = image_shape,))\n",
        "  \n",
        "  model.add(\n",
        "    tfk.layers.Conv2D(\n",
        "        filters = batch_size / 2**(num_ref_layer - counter_layer),\n",
        "        kernel_size = (3, 3), \n",
        "        activation='relu', \n",
        "        padding='same',\n",
        "        input_shape = image_shape,))\n",
        "   \n",
        "  model.add(\n",
        "      tfk.layers.MaxPooling2D(\n",
        "          pool_size = (2, 2),\n",
        "          padding='same',\n",
        "          ))\n",
        "\n",
        "  counter_layer += 1\n",
        "\n",
        "model.add(tfk.layers.Dropout(dropout_rate / 2))\n",
        "\n",
        "model.add(tfk.layers.Flatten())\n",
        "\n",
        "counter_layer = 0\n",
        "while counter_layer < num_ref_layer - 1:\n",
        "  model.add(\n",
        "      tfk.layers.Dense(\n",
        "          batch_size / 2**counter_layer, \n",
        "          activation='relu', \n",
        "          activity_regularizer = tfk.regularizers.l2(regularization_rate)\n",
        "          ))\n",
        "    \n",
        "  model.add(\n",
        "        tfk.layers.Dropout(dropout_rate)\n",
        "        )\n",
        "  \n",
        "  counter_layer += 1\n",
        "\n",
        "if num_classes <= 2:\n",
        "  model.add(\n",
        "      tfk.layers.Dense(num_classes, activation='sigmoid')\n",
        "      )\n",
        "  \n",
        "else:\n",
        "  model.add(\n",
        "      tfk.layers.Dense(num_classes, activation='softmax')\n",
        "      )"
      ],
      "metadata": {
        "id": "T457W9L4Qgth"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compiler:\n",
        "optimizer = tfk.optimizers.Adam(learning_rate=learning_rate)\n",
        "metrics = [\n",
        "    'Accuracy',\n",
        "    'AUC',\n",
        "    'Precision',\n",
        "    'Recall',\n",
        "    tfa.metrics.F1Score(num_classes=num_classes, average='micro'),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=class_mode + '_crossentropy',\n",
        "    metrics=metrics,\n",
        ")\n",
        "\n",
        "tensorboard_callback = tfk.callbacks.TensorBoard(log_dir=log_dir, write_graph=True)"
      ],
      "metadata": {
        "id": "4MdMQmoxQio6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training:\n",
        "\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            epochs = epochs,\n",
        "            steps_per_epoch = train_generator.samples // batch_size,\n",
        "            validation_data = validation_generator,\n",
        "            validation_steps = validation_generator.samples // batch_size,\n",
        "            class_weight = dict(enumerate(class_weights)),\n",
        "            callbacks = [tensorboard_callback]\n",
        "            )\n",
        "\n",
        "local_time = timestamp()\n",
        "local_model = model_dir / f\"model_{local_time}.h5\"\n",
        "local_weight_model = model_dir / f\"model_{local_time}_weights.h5\"\n",
        "\n",
        "model.save(local_model)\n",
        "model.save_weights(local_weight_model)"
      ],
      "metadata": {
        "id": "wkCbh7OBQkQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}